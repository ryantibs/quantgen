% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/quantile_lasso.R
\name{quantile_lasso}
\alias{quantile_lasso}
\title{Quantile lasso.}
\usage{
quantile_lasso(
  x,
  y,
  tau,
  lambda,
  weights = NULL,
  no_pen_vars = c(),
  intercept = TRUE,
  standardize = TRUE,
  noncross = FALSE,
  x0 = NULL,
  lp_solver = c("glpk", "gurobi"),
  time_limit = NULL,
  warm_starts = TRUE,
  params = list(),
  transform = NULL,
  inv_trans = NULL,
  jitter = NULL,
  verbose = FALSE
)
}
\arguments{
\item{x}{Matrix of predictors. If sparse, then passing it an appropriate 
sparse \code{Matrix} class can greatly help optimization.}

\item{y}{Vector of responses.}

\item{tau, lambda}{Vectors of quantile levels and tuning parameter values. If
these are not of the same length, the shorter of the two is recycled so
that they become the same length. Then, for each \code{i}, we solve a
separate quantile lasso problem at quantile level \code{tau[i]} and tuning
parameter value \code{lambda[i]}. The most common use cases are: specifying
one tau value and a sequence of lambda values; or specifying a sequence of
tau values and one lambda value.}

\item{weights}{Vector of observation weights (to be used in the loss
function). Default is NULL, which is interpreted as a weight of 1 for each
observation.}

\item{no_pen_vars}{Indices of the variables that should be excluded from the
lasso penalty. Default is \code{c()}, which means that no variables are to
be excluded.}
}
\value{
A list with the following components:
  \item{beta}{Matrix of lasso coefficients, of dimension = (number of
  features + 1) x (number of quantile levels) assuming \code{intercept=TRUE},
  else (number of features) x (number of quantile levels). Note: these
  coefficients will always be on the appropriate scale; they are always on
  the scale of original features, even if \code{standardize=TRUE}}
  \item{status}{Vector of status flags returned by Gurobi's or GLPK's LP
  solver, of length = (number of quantile levels)}
  \item{tau,lambda}{Vectors of tau and lambda values used}
  \item{weights,no_pen_vars,...,jitter}{Values of these other arguments  
  used in the function call}
}
\description{
Compute quantile lasso solutions.
}
\details{
This function solves the quantile lasso problem, for each pair of
  quantile level \eqn{\tau} and tuning parameter \eqn{\lambda}:  
  \deqn{\mathop{\mathrm{minimize}}_{\beta_0,\beta} \;
  \sum_{i=1}^n w_i \psi_\tau(y_i-\beta_0-x_i^T\beta) + \lambda \|\beta\|_1}    
  for a response vector \eqn{y} with components \eqn{y_i}, and predictor
  matrix \eqn{X} with rows \eqn{x_i}. Here \eqn{\psi_\tau(v) = \max\{\tau v, 
  (\tau-1) v\}} is the "pinball" or "tilted \eqn{\ell_1}" loss. When
  noncrossing constraints are applied, we instead solve one big joint
  optimization, over all quantile levels and tuning parameter values: 
  \deqn{\mathop{\mathrm{minimize}}_{\beta_{0k}, \beta_k, k=1,\ldots,r} \; 
  \sum_{k=1}^r \bigg(\sum_{i=1}^n w_i \psi_{\tau_k}(y_i-\beta_{0k}-
  x_i^T\beta_k) + \lambda_k \|\beta_k\|_1\bigg)} 
  \deqn{\mathrm{subject \; to} \;\; \beta_{0k}+x^T\beta_k \leq
  \beta_{0,k+1}+x^T\beta_{k+1} \;\; k=1,\ldots,r-1, \; x \in \mathcal{X}}
  where the quantile levels \eqn{\tau_j, j=1,\ldots,k} are assumed to be in
  increasing order, and \eqn{\mathcal{X}} is a collection of points over
  which to enforce the noncrossing constraints.

  Either problem is readily converted into a linear program (LP), and solved
  using either Gurobi (which is free for academic use, and generally fast) or
  GLPK (which free for everyone, but slower).

  All arguments not described above are as in the \code{quantile_genlasso}
  function. The associated \code{coef} and \code{predict} functions are just
  those for the \code{quantile_genlasso} class.
}
\author{
Ryan Tibshirani
}
